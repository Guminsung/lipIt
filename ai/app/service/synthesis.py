# app/service/synthesis.py

import os
import time

import torch
from app.core.tts_model import get_tts, reload_tts
from app.service.celeb_tts import run_celeb_tts
from app.service.clean_audio import clean_wav
from app.util.file_cache import get_cached_speaker_wav
from app.util.latents import (
    get_gpt_latent_per_chunk,
    get_latents,
    get_speaker_embedding,
)
from app.util.stream import celeb_wav_to_bytes, wav_to_bytes


def synthesize_voice(
    text: str,
    output_path: str,
    clean: bool = True,
    language: str = "en",
    length_scale: float = 0.1,
    noise_scale: float = 0.4,
    noise_scale_dp: float = 0.5,
) -> str:
    """
    TTS ìŒì„± í•©ì„± í•¨ìˆ˜

    Args:
        text (str): ìƒì„±í•  í…ìŠ¤íŠ¸
        output_path (str): ì €ì¥í•  .wav ê²½ë¡œ
        clean (bool): í›„ì²˜ë¦¬ ì—¬ë¶€
    Returns:
        str: ìµœì¢… ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """

    # GPU ë™ê¸°í™” ì „í›„ ì‹œê°„ ì¸¡ì •
    start = time.time()

    torch.cuda.synchronize()

    tts = get_tts()
    latents = get_latents()

    tts.synthesizer.tts_model.length_scale = length_scale  # ìˆ«ìê°€ ì‘ì„ìˆ˜ë¡ ë” ë¹ ë¦„
    tts.synthesizer.tts_model.noise_scale = noise_scale
    tts.synthesizer.tts_model.noise_scale_dp = noise_scale_dp

    result = tts.synthesizer.tts_model.inference(
        text=text,
        language=language,
        gpt_cond_latent=latents["gpt"],
        speaker_embedding=latents["d_vector"],
    )

    print(f"ğŸ”Š Inference ì™„ë£Œ ì‹œê°„: {time.time() - start:.2f}ì´ˆ")

    wav = result["wav"]

    tmp_path = output_path
    if clean:
        tmp_path = f"/tmp/tts_{os.getpid()}.wav"

    tts.synthesizer.save_wav(wav=wav, path=tmp_path)

    if clean:
        clean_wav(tmp_path, output_path)
        os.remove(tmp_path)

    return output_path


def synthesize_voice_latents(
    text: str,
    output_path: str,
    voice_id: int,
    voice_url: str,
):
    if not voice_id or not voice_url:
        raise ValueError("voice_idì™€ voice_urlì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")

    language = "en"
    length_scale = 1.2
    noise_scale = 0.667
    noise_scale_dp = 0.8

    try:
        start = time.time()
        # torch.cuda.synchronize()

        # ì…€ëŸ½ ëª©ì†Œë¦¬
        if voice_id == 1:
            wav = run_celeb_tts(text)
            audio_bytes = celeb_wav_to_bytes(wav, 22050)
        else:
            # ì»¤ìŠ¤í…€ ëª©ì†Œë¦¬
            tts = get_tts()
            xtts_model = tts.synthesizer.tts_model

            # xtts_model.length_scale = length_scale
            # xtts_model.noise_scale = noise_scale
            # xtts_model.noise_scale_dp = noise_scale_dp
            xtts_model.config.audio["sample_rate"] = 24000

            latents = get_latents(voice_id, voice_url)

            result = xtts_model.inference(
                text=text,
                language=language,
                gpt_cond_latent=latents["gpt"],
                speaker_embedding=latents["d_vector"],
            )

            wav = result["wav"]

            # ë©”ëª¨ë¦¬ì—ì„œ ë°”ë¡œ WAV ë³€í™˜
            audio_bytes = wav_to_bytes(wav, 24000)

            # GPU í…ì„œë¥¼ ì œê±°í•˜ê³  PyTorchê°€ ì¡ê³  ìˆëŠ” ë©”ëª¨ë¦¬ ë¸”ë¡ë„ ë°˜ë‚©
            del result
            del latents

        print(f"ğŸ”Š Inference ì™„ë£Œ ì‹œê°„: {time.time() - start:.2f}ì´ˆ")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del wav
        torch.cuda.empty_cache()

        return audio_bytes

        # wav íŒŒì¼ ë””ìŠ¤í¬ì— ì €ì¥
        # wav = result["wav"]
        # tts.synthesizer.save_wav(wav=wav, path=output_path)

        # print(f"ğŸ”Š Inference ì™„ë£Œ ì‹œê°„: {time.time() - start:.2f}ì´ˆ")
    except RuntimeError as e:
        if "indexSelectSmallIndex" in str(e) or "CUDA error" in str(e):
            print(f"âš ï¸ GPU ì˜¤ë¥˜ ë°œìƒ: {e}")

            print(torch.cuda.is_available())  # Falseë©´ ì´ë¯¸ context ì£½ìŒ
            print(torch.cuda.memory_summary())  # í˜„ì¬ ìƒíƒœ ìš”ì•½

            reload_tts()
            # ì¬ì‹œë„ í•œ ë²ˆë§Œ
            return synthesize_voice_latents(text, "", voice_id, voice_url)
        else:
            raise e
