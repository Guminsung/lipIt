# app/main.py

from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
import os
import time

from app.api.v1.ws_call import router
from app.core.synthesizer import get_cached_synthesizer
from app.core.tts_model import load_tts


# ========== Monkey Patch ì ìš© ==========
def monkey_patch_check_arguments():
    from TTS.api import TTS
    from TTS.tts.models import xtts
    from TTS.tts.models.xtts import Xtts
    from TTS.utils.synthesizer import Synthesizer
    import torch

    # 1. TTS._check_arguments íŒ¨ì¹˜
    def _patched_check_arguments(
        self, speaker=None, language=None, speaker_wav=None, emotion=None, **kwargs
    ):
        if self.is_multi_speaker and (
            speaker is None and speaker_wav is None and "d_vector" not in kwargs
        ):
            raise ValueError(
                "Model is multi-speaker but no speaker, speaker_wav, or d_vector provided."
            )
        if self.is_multi_lingual and language is None:
            raise ValueError("Model is multi-lingual but no language provided.")
        if (
            not self.is_multi_speaker
            and speaker is not None
            and "voice_dir" not in kwargs
        ):
            raise ValueError("Model is not multi-speaker but speaker is provided.")
        if not self.is_multi_lingual and language is not None:
            raise ValueError("Model is not multi-lingual but language is provided.")
        if emotion is not None:
            raise ValueError("Emotion can only be used with Coqui Studio models.")

    TTS._check_arguments = _patched_check_arguments
    print("âœ… Monkey patched: TTS._check_arguments")

    # 2. XTTS ë‚´ë¶€ d_vector í—ˆìš© íŒ¨ì¹˜
    def _patched_get_conditioning_latents(self, file_path, load_sr, d_vector=None):
        if d_vector is not None:
            print("ğŸ™ï¸ Using d_vector instead of speaker_wav")
            speaker_embedding = d_vector.to(self.device)
            # 3Dë¡œ ë°”ê¿”ì•¼ GPTì—ì„œ concatí•  ë•Œ ì˜¤ë¥˜ ì•ˆ ë‚¨
            gpt_cond_latent = torch.zeros(
                (1, 1, 1024), dtype=speaker_embedding.dtype, device=self.device
            )
            return gpt_cond_latent, speaker_embedding
        return xtts.original_get_conditioning_latents(self, file_path, load_sr)

    def _patched_full_inference(
        self, text, speaker_wav, language, d_vector=None, **kwargs
    ):
        gpt_cond_latent, speaker_embedding = self.get_conditioning_latents(
            speaker_wav,
            24000,
            d_vector=d_vector,
        )

        # HuggingFace generate ì˜¤ë¥˜ ë°©ì§€
        if "config" in kwargs:
            kwargs.pop("config")

        outputs = self.inference(
            text,
            language,
            gpt_cond_latent,
            speaker_embedding,
            **kwargs,
        )
        return outputs["wav"]  # wavë§Œ ë¦¬í„´

    def _patched_synthesize(self, text, speaker_wav, language, **kwargs):
        if "d_vector" not in kwargs and speaker_wav is None:
            raise ValueError(
                "[patched] Multi-speaker XTTS ëª¨ë¸ì€ `speaker_wav` ë˜ëŠ” `d_vector` ì¤‘ í•˜ë‚˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            )
        return self.full_inference(text, speaker_wav, language, **kwargs)

    if not hasattr(Xtts, "_original_synthesize"):
        xtts.original_get_conditioning_latents = Xtts.get_conditioning_latents

    Xtts.get_conditioning_latents = _patched_get_conditioning_latents
    Xtts.full_inference = _patched_full_inference
    Xtts.synthesize = _patched_synthesize
    print("âœ… Monkey patched: XTTS")

    # 3. Synthesizer.tts íŒ¨ì¹˜ (ìµœì¢… ì˜ˆì™¸ ë°©ì§€)
    def _patched_synthesizer_tts(
        self,
        text,
        speaker_name=None,
        language_name=None,
        speaker_wav=None,
        d_vector=None,
        split_sentences=True,
        **kwargs,
    ):
        if self.tts_model is None:
            raise RuntimeError("âŒ tts_modelì´ Noneì…ë‹ˆë‹¤. checkpoint ë¡œë”© ì‹¤íŒ¨")

        # âœ… ë‹¨ì¼ í™”ì (VITS) ëª¨ë¸ì´ë©´ Synthesizer ì›ë˜ ë¡œì§ì„ ì“°ì
        if not getattr(self.tts_model, "is_multi_speaker", False):
            # Synthesizer ì›ë˜ ë°©ì‹ í˜¸ì¶œ (patch ì•ˆ í•¨)
            return Synthesizer._original_tts(self, text)

        # âœ… XTTS (ë©€í‹° í™”ì) ëª¨ë¸
        if speaker_wav is None and d_vector is None:
            raise ValueError("XTTSëŠ” speaker_wav ë˜ëŠ” d_vectorê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        return self.tts_model.synthesize(
            text,
            speaker_wav,
            language_name,
            d_vector=d_vector,
            **kwargs,
        )

    # í•œë²ˆë§Œ íŒ¨ì¹˜
    if not hasattr(Synthesizer, "_original_tts"):
        Synthesizer._original_tts = Synthesizer.tts
        Synthesizer.tts = _patched_synthesizer_tts
        print("âœ… Monkey patched: Synthesizer.tts (VITS + XTTS í˜¸í™˜)")


# ========== Lifespan ==========
async def lifespan(app: FastAPI):
    start = time.time()
    monkey_patch_check_arguments()
    load_tts()
    get_cached_synthesizer()  # ëª¨ë¸ ë©”ëª¨ë¦¬ì— ë¡œë”©
    print(f"âœ… TTS ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time.time() - start:.2f}ì´ˆ)")

    print("ğŸŸ¢ ì„œë²„ ì¤€ë¹„ ì™„ë£Œ âœ… ì´ì œ WebSocket ì—°ê²° ê°€ëŠ¥")
    yield


# ========== FastAPI ì•± ==========
app = FastAPI(lifespan=lifespan)

# API ë¼ìš°í„° ë“±ë¡
app.include_router(router)
